{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMI2k-oBsS08"
   },
   "source": [
    "_Lambda School Data Science — Model Validation_ \n",
    "\n",
    "# Validate classification problems\n",
    "\n",
    "Objectives\n",
    "- Imbalanced Classes\n",
    "- Confusion Matrix\n",
    "- ROC AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUZCkblZYN60"
   },
   "source": [
    "Reading\n",
    "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rU7RuVcjWdcp"
   },
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jes2WnwV072n"
   },
   "source": [
    "We'll use [mlxtend](http://rasbt.github.io/mlxtend/) and [yellowbrick](http://www.scikit-yb.org/en/latest/) for visualizations. These libraries are already installed on Google Colab. But if you are running locally with Anaconda Python, you'll probably need to install them:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge mlxtend \n",
    "conda install -c districtdatalabs yellowbrick\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQYGb3HgEp8b"
   },
   "source": [
    "We'll reuse the `train_validation_test_split` function from yesterday's lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMTjC3vQ7ZNV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, \n",
    "    random_state=None, shuffle=True):\n",
    "        \n",
    "    assert train_size + val_size + test_size == 1\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_size/(train_size+val_size), \n",
    "        random_state=random_state, shuffle=shuffle)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWLBlu5K5kJR"
   },
   "source": [
    "## Fun demo!\n",
    "\n",
    "The next code cell does five things:\n",
    "\n",
    "#### 1. Generate data\n",
    "\n",
    "We use scikit-learn's [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to generate fake data for a binary classification problem, based on several parameters, including:\n",
    "- Number of samples\n",
    "- Weights, meaning \"the proportions of samples assigned to each class.\"\n",
    "- Class separation: \"Larger values spread out the clusters/classes and make the classification task easier.\"\n",
    "\n",
    "(We are generating fake data so it is easy to visualize.)\n",
    "\n",
    "#### 2. Split data\n",
    "\n",
    "We split the data three ways, into train, validation, and test sets. (For this toy example, it's not really necessary to do a three-way split. A two-way split, or even no split, would be ok. But I'm trying to demonstrate good habits, even in toy examples, to avoid confusion.)\n",
    "\n",
    "#### 3. Fit model\n",
    "\n",
    "We use scikit-learn to fit a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the training data.\n",
    "\n",
    "We use this model parameter:\n",
    "\n",
    "> **class_weight : _dict or ‘balanced’, default: None_**\n",
    "\n",
    "> Weights associated with classes in the form `{class_label: weight}`. If not given, all classes are supposed to have weight one.\n",
    "\n",
    "> The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`.\n",
    "\n",
    "\n",
    "#### 4. Evaluate model\n",
    "\n",
    "We use our Logistic Regression model, which was fit on the training data, to generate predictions for the validation data.\n",
    "\n",
    "Then we print [scikit-learn's Classification Report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), with many metrics, and also the accuracy score. We are comparing the correct labels to the Logistic Regression's predicted labels, for the validation set. \n",
    "\n",
    "#### 5. Visualize decision function\n",
    "\n",
    "Based on these examples\n",
    "- https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html\n",
    "- http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-1-decision-regions-in-2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcpoWCUq5xNV"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "#1. Generate data\n",
    "\n",
    "# Try re-running the cell with different values for these parameters\n",
    "n_samples = 1000\n",
    "weights = (0.50, 0.50)\n",
    "class_sep = 0.8\n",
    "\n",
    "X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_repeated=0, n_classes=2, \n",
    "                           n_clusters_per_class=1, weights=weights, \n",
    "                           class_sep=class_sep, random_state=0)\n",
    "\n",
    "\n",
    "# 2. Split data\n",
    "\n",
    "# Uses our custom train_validation_test_split function\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, train_size=0.8, val_size=0.1, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "# 3. Fit model\n",
    "\n",
    "# Try re-running the cell with different values for this parameter\n",
    "class_weight = None\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', class_weight=class_weight)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 4. Evaluate model\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('accuracy', accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "# 5. Visualize decision regions\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_decision_regions(X_val, y_val, model, legend=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrllN3yECsEN"
   },
   "source": [
    "Try re-running the cell above with different values for these four parameters:\n",
    "- `n_samples`\n",
    "- `weights`\n",
    "- `class_sep`\n",
    "- `class_balance`\n",
    "\n",
    "For example, with a 50% / 50% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.50, 0.50)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With a 95% / 5% class distribution:\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = None\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but changing the Logistic Regression's `class_balance` parameter to `'balanced'` (instead of its default `None`)\n",
    "```\n",
    "n_samples = 1000\n",
    "weights = (0.95, 0.05)\n",
    "class_sep = 0.8\n",
    "class_balance = 'balanced'\n",
    "```\n",
    "\n",
    "With the same 95% / 5% class distribution, but with different values for `class_balance`:\n",
    "- `{0: 1, 1: 1}` _(equivalent to `None`)_\n",
    "- `{0: 1, 1: 2}`\n",
    "- `{0: 1, 1: 10}` _(roughly equivalent to `'balanced'` for this dataset)_\n",
    "- `{0: 1, 1: 100}`\n",
    "- `{0: 1, 1: 10000}`\n",
    "\n",
    "How do the evaluation metrics and decision region plots change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-3MS-jANssN"
   },
   "source": [
    "## What you can do about imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwgStd-yUUr"
   },
   "source": [
    "[Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/) gives \"a rough outline of useful approaches\" : \n",
    "\n",
    "- Do nothing. Sometimes you get lucky and nothing needs to be done. You can train on the so-called natural (or stratified) distribution and sometimes it works without need for modification.\n",
    "- Balance the training set in some way:\n",
    "  - Oversample the minority class.\n",
    "  - Undersample the majority class.\n",
    "  - Synthesize new minority classes.\n",
    "- Throw away minority examples and switch to an anomaly detection framework.\n",
    "- At the algorithm level, or after it:\n",
    "  - Adjust the class weight (misclassification costs).\n",
    "  - Adjust the decision threshold.\n",
    "  - Modify an existing algorithm to be more sensitive to rare classes.\n",
    "- Construct an entirely new algorithm to perform well on imbalanced data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iO7kOZ2HN0EA"
   },
   "source": [
    "We demonstrated just one of these options: many scikit-learn classifiers have a `class_balance` parameter, which we can use to \"adjust the class weight (misclassification costs).\"\n",
    "\n",
    "The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\"\n",
    "\n",
    "You can see how to \"adjust the decision threshold\" in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xhh5TiW_X1_Q"
   },
   "source": [
    "## Bank Marketing — getting started\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Bank+Marketing\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n",
    "\n",
    "bank-additional-full.csv with all examples (41188) and 20 inputs, **ordered by date (from May 2008 to November 2010)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n18wVnuxY-xl"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-oHbkK1X1h2"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "1INLmiipZA-y"
   },
   "outputs": [],
   "source": [
    "!unzip bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwWCY5XrZCWk"
   },
   "outputs": [],
   "source": [
    "%cd bank-additional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zf49DcHTZPdE"
   },
   "source": [
    "### Load data, assign to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwhVgENcZEwo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bank = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "X = bank.drop(columns='y')\n",
    "y = bank['y'] == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lq1it0dnZlX3"
   },
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-FgY4pIaEXo"
   },
   "source": [
    "We want to do \"model selection (hyperparameter optimization) and performance estimation\" so we'll choose a validation method from the diagram's green box.\n",
    "\n",
    "There is no one \"right\" choice here, but I'll choose \"3-way holdout method (train/validation/test split).\"\n",
    "  \n",
    "<img src=\"https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg\" width=\"600\">\n",
    "\n",
    "Source: https://sebastianraschka.com/blog/2018/model-evaluation-selection-part4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V74i3GDcZnkm"
   },
   "source": [
    "There's no one \"right\" choice here, but I'll choose to split by time, not with a random shuffle, based on this advice by [Rachel Thomas](\n",
    "https://www.fast.ai/2017/11/13/validation-sets/):\n",
    "> If your data is a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates your are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future).\n",
    "\n",
    "[According to UCI](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing), this data is \"ordered by date (from May 2008 to November 2010)\" so if I don't shuffle it when splitting, then it will be split by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xnw-vfOamHH"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_validation_test_split(\n",
    "    X, y, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12dWJxXabDxt"
   },
   "source": [
    "## Bank Marketing — live coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAPOJu3uamrU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_XjBTW5SBwZ"
   },
   "source": [
    "# ASSIGNMENT options\n",
    "\n",
    "Replicate code from the lesson or other examples. [Do it \"the hard way\" or with the \"Benjamin Franklin method.\"](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit)\n",
    "\n",
    "Work with one of these datasets\n",
    "- [Bank Marketing](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)\n",
    "- [Synthetic Financial Dataset For Fraud Detection](https://www.kaggle.com/ntnu-testimon/paysim1)\n",
    "- Any imbalanced binary classification dataset\n",
    "\n",
    "Continue improving your model. Measure validation performance with a variety of classification metrics, which could include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- ROC AUC\n",
    "\n",
    "Try one of the other options mentioned for imbalanced classes\n",
    "- The [imbalance-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library can be used to \"oversample the minority class, undersample the majority class, or synthesize new minority classes.\"\n",
    "- You can see how to \"adjust the decision threshold\" in a great blog post, [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_242_Validate_classification_problems.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
